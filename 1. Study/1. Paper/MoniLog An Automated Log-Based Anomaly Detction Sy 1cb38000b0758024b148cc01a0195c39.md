# MoniLog: An Automated Log-Based Anomaly Detction System for Cloud Computing Infrastures

---

## Abstract

오늘날의 대규모 시스템에서는 하나의 이상(anomaly)으로 인해 수백만 명의 사용자에게 영향을 미칠 수 있습니다. 이러한 이벤트를 실시간으로 탐지하는 것은 서비스 품질을 유지하기 위해 필수적입니다. 이는 모니터링 팀이 장애의 영향을 사전에 방지하거나 최소화할 수 있도록 해줍니다. 로그는 소프트웨어 개발과 유지보수에서 핵심적인 요소로, 실행 중의 상세한 정보를 기록합니다. 이러한 로그 데이터는 거의 모든 컴퓨터 시스템에서 보편적으로 제공되며, 개발자와 시스템 관리자 모두가 이상 이벤트를 모니터링하고 분석하는 데 활용됩니다. 클라우드 컴퓨팅 기업이나 대규모 온라인 플랫폼의 경우, 성장은 확장 가능성과 밀접한 연관이 있습니다. 이상 탐지 과정을 자동화하는 것은 현대 시스템에서 생성되는 증가하는 로그의 양에 대응하여 모니터링 역량의 확장성을 보장할 수 있는 유망한 방법입니다. 본 논문에서는 대규모 환경에서 실시간 이상을 탐지하기 위한 분산 접근 방식인 **MoniLog**를 소개합니다. MoniLog는 다중 소스 로그 스트림 내에서 순차적 및 정량적 이상을 탐지하는 것을 목표로 합니다. 이 시스템은 로그 스트림을 구조화하고 이상 시퀀스의 모니터링을 수행하도록 설계되었습니다. 또한 출력 분류기는 관리자의 조치로부터 학습하여 이상 상황의 중요도 수준을 분류하고 평가합니다.

## I. INTRODUCTION

클라우드 컴퓨팅 플랫폼은 필요할 때마다 IT 자원을 제공받을 수 있도록 해줍니다. 이러한 아웃소싱은 클라우드 제공업체가 고객 서비스의 **고가용성(high availability)** 및 **품질**을 책임지게 만듭니다. 이러한 대규모 온라인 시스템에서는 하나의 사건이 수백만 명의 사용자에게 영향을 미칠 수 있습니다 [1]–[3]. **이상 탐지(anomaly detection)**는 안전하고 신뢰할 수 있는 플랫폼을 구축하기 위한 핵심 단계입니다. 이상 시퀀스를 적시에 정확하게 탐지함으로써 운영팀은 손실을 줄일 수 있습니다 [4]. 실행 시간(runtime) 정보를 기록하는 것은 소프트웨어 시스템에서 일반적인 관행입니다 [5]. 생성된 로그는 시스템 상태의 다양한 변화와 더불어 광범위한 이벤트를 설명합니다. 그 단순성과 효과성 덕분에, 로깅(logging)은 실무에서 널리 채택되어 왔습니다 [6]. 따라서 로그는 **이상 탐지를 위한 가장 가치 있는 데이터 소스 중 하나**로 간주됩니다 [7]–[9]. 시스템 유지 관리자와 개발자는 로그를 활용하여 시스템의 상태를 이해하고, 장애의 원인을 식별하며 [10]–[12], 성능 문제를 분석하고 [13], [14], 보안 공격을 방지합니다 [15].

대규모 서비스와 그 기반 시스템의 개발은 일반적으로 수백 명의 인력들이 여러 팀, 때로는 서로 다른 조직 구조로 나뉘어 수행됩니다. 개발자나 운영자는 전체 시스템에 대한 정보를 완전히 파악하지 못하는 경우가 많으며, **국지적인(local) 관점**에서 이상 로그를 판단하는 경향이 있어 오류가 발생하기 쉽습니다. 또한, 현대 시스템에서 생성되는 로그의 양이 지속적으로 증가함에 따라, **이상 로그 시퀀스를 수동으로 탐지하는 방식은 비효율적일 뿐만 아니라 확장성도 부족합니다.**

키워드 매칭(keyword matching)이나 정규 표현식(regular expression)을 활용하면 단순하고 잘 알려진 이상 이벤트는 탐지할 수 있습니다. 그러나 많은 이상 현상은 단일 로그가 아닌, **정상적으로 보이는 로그들이 연속되어 발생한 후 바람직하지 않은 결과로 이어지는 형태**이기 때문에, 이러한 방식만으로는 대부분의 이상을 식별할 수 없습니다.

자동화된 로그 기반 이상 탐지는 활발히 연구되고 있는 분야입니다. 신뢰할 수 있고 실시간 대응이 가능한 솔루션의 필요성에 따라 다양한 접근 방식이 등장하고 있습니다 [9], [16]–[19].

로그는 **메시지 필드에 자유 형식의 텍스트를 포함하는 반구조화(semi-structured) 문자열**입니다. 이러한 형식은 사람이 읽고 검사하기에는 편리하지만, **자동화된 분석**에는 적합하지 않습니다. 기존의 로그 기반 이상 탐지 접근법들은 **로그 메시지를 구조화하는 것의 중요성**을 강조하고 있습니다 [10].

- *3DS OUTSCALE [20]**은 프랑스의 멀티 소버린(Multisovereign) 클라우드 서비스를 제공하는 회사입니다. 이 회사는 자사 클라우드 컴퓨팅 플랫폼을 구성하는 다양한 시스템들을 모니터링하기 위해 로그를 광범위하게 사용하고 있습니다. 모니터링 외에도, 로그는 가상 머신 충돌이나 악의적인 보안 이벤트와 같은 **바람직하지 않은 결과를 식별**하는 데에도 활용됩니다.

본 논문에서는 **이상 탐지에 관한 연구**를 통해 **운영 효율성을 향상**시키고, **회사가 추구하는 고가용성 및 보안 수준**을 강화하는 데 기여하고자 합니다.

우리의 클라우드 컴퓨팅 플랫폼 내에서 로깅(logging)은 다음과 같은 특징을 가집니다:

1. 개발 팀은 **지속적 통합(Continuous Integration)** [21] 방식을 소프트웨어 전달 모델로 사용합니다. 이는 소프트웨어 개발에서 일반적으로 사용되는 관행이며, 새로운 기능을 빠르게 출시할 수 있는 훌륭한 방법입니다. 그러나 이러한 방식은 코드베이스와 로그 문장이 빠르게 변화하게 만들어, **로그 스트림 내에 불안정성**을 유발할 수 있습니다 [22].
2. **로그 소스와 서로 다른 저장 시스템 간의 물리적 거리**는 일정하지 않습니다. 이러한 구성은 **노이즈(noise)**를 발생시키며, 그 결과 **로그가 순서가 섞인 상태로 도착하거나, 때로는 중복**되어 수집되기도 합니다.

이상(anomaly)과 관련하여, 일부 이상은 **다중 소스 관점(multi-source scope)**에서만 탐지할 수 있습니다. 예를 들어, **저장소 로그(storage logs)** 내의 특정 패턴은, 동시에 네트워크 로그(network logs)에서 특정 행동이 기록될 때에만 이상으로 간주됩니다. 이러한 사례는 **견고하고 자동화된 이상 탐지 시스템을 구축하는 것의 중요성**을 다시금 강조해줍니다 [9].

우리의 박사 연구(Ph.D.) 동기는 **MoniLog**를 제안하는 데에 있습니다. MoniLog는 **클라우드 컴퓨팅의 제약 조건과 대규모 온라인 플랫폼 전반에 적응할 수 있도록 설계된 자율적인(logs 기반의) 이상 탐지 시스템**입니다. 이는 로그를 **견고하고 확장 가능하게 파싱(parsing) 및 분석**할 수 있을 뿐만 아니라, 탐지된 이상을 분류(classify)하는 기능도 제공합니다.

우리는 설계를 **II장에서 제시한 3단계 접근 방식**에 기반하여 진행하였습니다. III장, IV장, V장은 각각 이 접근 방식의 각 단계에 해당하는 내용을 다루고 있으며, 해당 장들에서는 관련 기술의 최신 동향(state of the art)과 **박사 연구를 통해 계획된 기여 내용**을 설명합니다.

우리의 연구는 클라우드 컴퓨팅 분야의 제약과 요구사항에서 강한 동기를 얻었지만, 이러한 문제들은 거의 모든 **대규모·복합·온라인 시스템**에서 공통적으로 존재합니다. 따라서 MoniLog는 **클라우드 환경에 국한된 도구가 아니라**, **제약이 있는 환경에서 이상 상황을 처리하기 위한 견고한 솔루션**으로 발전하는 것을 목표로 합니다.

## II. MONILOG DESIGN

![image.png](image.png)![image](https://github.com/user-attachments/assets/676f599e-0659-4dae-9133-ed44f138c892)


대규모 시스템은 종종 여러 개의 소프트웨어로 구성되어 있습니다. 이러한 **복합적인 구조**로 인해, 시스템은 **다양한 로그 소스**에 연결되어 있습니다. 예를 들어 **3DS OUTSCALE**에서는 하나의 시스템이 **24개의 서로 다른 로그 소스**와 연결되어 있으며, **매초 수백만 줄의 로그를 생성**합니다.

이를 표현하기 위해 우리는 MoniLog의 입력을 여러 로그 소스에서 공급되는 로그 스트림(log stream)으로 모델링했습니다.

MoniLog 구성 요소들이 **분산(distributable)** 가능한 형태로 설계되는 것은 매우 중요합니다. 이는 대부분의 온라인 서비스 기업들에게 있어 성장의 핵심 요소인 확장성(scalability)을 보장하기 위함입니다.

MoniLog의 목표 출력은 분류된 이상(anomalies)들의 스트림이며, 각각에 위험도(criticality)가 할당되어 있습니다. 이를 달성하기 위해, 우리는 3단계 시스템(Figure 1)을 설계하였습니다.

1. **파싱(parsing) 컴포넌트**: 로그의 내재된 정보를 추출하여 구조화된 로그 스트림(structured log-stream)을 생성합니다.
2. **이상 탐지 컴포넌트**: 구조화된 로그 스트림 내에서 이상을 탐지합니다. 이 구성 요소는 식별된 이상 시퀀스와 관련된 모든 로그를 포함한 이상 보고서(anomaly reports)를 생성합니다.
3. **분류기(classifier)**: 탐지된 이상(anomalies)에 대해 유형(type)과 위험도 수준(level of criticality)을 할당하는 역할을 합니다. 이상 유형과 위험도 수준은 **모니터링 팀에 의해 정의**됩니다. 이 모듈은 **관리자의 행동을 관찰함으로써(Section V)** **수동적으로 학습**합니다.

## III. LOG-BASED ANOMALY DETECTION

![image.png](image%201.png)

프로그램은 일반적으로 고정된 흐름(flow)에 따라 실행되며, 로그는 이러한 실행 순서에 따라 생성됩니다. 로그와 관련된 이상 이벤트는 **크게 두 가지 유형**으로 나눌 수 있습니다:

1. **순차적 이상(Sequential anomalies)**: 로그 시퀀스가 정상적인 흐름에서 벗어날 때 발생합니다.
    
    예: *표 I에서* `L1 → L4 → L2` 와 같은 경우.
    
2. **정량적 이상(Quantitative anomalies)**: 정상적인 흐름을 따르지만, **비정상적인 값**으로 인해 **바람직하지 않은 결과**를 초래하는 경우입니다.
    
    예: `L3`
    

기존의 **로그 기반 이상 탐지 솔루션**들은 **두 가지 범주**로 분류될 수 있습니다:

1. **로그 메시지 카운터 기반 접근 방식**
    
    예: PCA [16], Invariant Mining(IM) [17], LogClustering [18]
    
2. **딥러닝 기반 접근 방식**
    
    예: DeepLog [19], LogRobust [9], LogAnomaly [23]
    

이들을 비교하기 위해, 우리는 다음과 같은 평가 지표(metrics)를 고려하였습니다:
로그 내에서 이상을 탐지하기 위한 기존 솔루션들은 **두 가지 범주**로 분류할 수 있습니다. 하나는 **로그 메시지 개수 기반 접근 방식**(예: 주성분 분석(Principal Component Analysis) [16], 불변성 마이닝(Invariant Mining) [17], 로그 클러스터링(Log Clustering) [18])이고, 다른 하나는 **심층 학습 기반 접근 방식**(예: 딥로그(DeepLog) [19], 로그로버스트(LogRobust) [9], 로그어노말리(LogAnomaly) [23])입니다.

- **정밀도(Precision)**: 모델이 이상으로 식별한 로그 시퀀스 중에서 실제로 이상인 로그 시퀀스의 비율입니다.
    
    정밀도 = 참 양성(TP) / (참 양성(TP) + 거짓 양성(FP))
    
    **Precision = TP / (TP + FP)**
    
- **재현율(Recall)**: 실제 이상 로그 시퀀스 중에서 모델이 정확하게 이상으로 식별한 비율입니다.
    
    재현율 = 참 양성(TP) / (참 양성(TP) + 거짓 음성(FN))
    
    **Recall = TP / (TP + FN)**
    
- **F1 점수(F1-score)**: 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 평가합니다.
    
    **F1-score = 2 × (Precision × Recall) / (Precision + Recall)**
    

TP는 모델에 의해 **정확하게 탐지된 이상 로그 시퀀스의 수**를 나타내고, FP는 모델에 의해 **잘못 이상으로 식별된 정상 로그 시퀀스의 수**를 나타내며, FN은 모델에 의해 **탐지되지 않은 이상 로그 시퀀스의 수**를 나타냅니다.

가장 최신이며 유망한 방법들은 **심층 학습(Deep Learning)** 기법을 기반으로 합니다.

**DeepLog**, **LogAnomaly**, **LogRobust**는 **장단기 기억 신경망(Long Short-Term Memory Neural Network, LSTM)** [24], [25]을 사용하며, 이는 **순환 신경망(Recurrent Neural Network, RNN)** 모델의 변형입니다.

LSTM 네트워크는 이전 상태의 출력을 현재 입력으로 전달하기 위해 루프 구조(loop)를 사용합니다.

이러한 구조는 **정상 실행 흐름 내의 순차적 패턴을 학습하는 데 효율적**입니다.

DeepLog는 정량적 이상(quantitative anomalies)을 탐지하기 위해 두 번째 장단기 기억 신경망(Long Short-Term Memory, LSTM)을 사용한다. 이 모델은 **이미 관측된 값들에 대한 학습된 지식**을 기반으로 새로운 값이 **예상 범위 내에 있는지 여부**를 판단한다.

LSTM 네트워크는 고정 길이 벡터(fixed-length vector)를 입력으로 받는다. DeepLog의 경우, 이 벡터의 길이는 **학습 데이터셋에 존재하는 로그 파서(log parser)에 의해 식별된 로그 패턴의 개수**를 나타낸다.

이 방식은 로그 문장이 변경되지 않는다는 폐쇄 세계 가정(closed-world assumption)이 전제될 때 유효하다. 그러나 본 연구에서 고려하는 환경에서는 지속적 통합(continuous integration)으로 인해 로그 문장이 언제든지 추가, 삭제 또는 수정될 수 있으므로 이러한 가정이 성립하지 않는다.

로그 템플릿의 불안정성(log template instability)에 대응하기 위해, **LogRobust**는 로그 개수 벡터(log count vector)를 신경망에 입력으로 사용한다. 이 벡터는 의미 벡터화(semantic vectorization)라 불리는 단계에서 생성되며 [9], 이 과정에서는 토큰(token) 간의 **의미적 관계**를 활용하여 고정 길이 벡터(fixed-length vector)를 생성한다.

이 방법은 새로운 로그 템플릿을 **벡터의 길이를 변경하지 않고** 벡터화할 수 있도록 한다.

자신들의 접근 방식을 테스트하기 위해, **LogRobust의 저자들**은 **HDFS 데이터셋**의 여러 변형 버전을 사용하였다. 각 버전은 0%에서 20% 사이의 비율로 불안정한 로그 이벤트(unstable log events)를 포함하고 있다.

**현실 세계에서 발생할 수 있는 로그의 불안정성**을 반영하기 위해 다양한 유형의 이벤트가 구성되었다:

- **잘못 파싱된 로그라인**: 로그 파싱 오류를 시뮬레이션하기 위해 사용됨
- **기존 로그 문장을 변형하여 생성한 로그라인**: 코드 수정 상황을 시뮬레이션
- **중복되거나 순서가 뒤섞인 로그**: 실제 운영 환경에서 발생할 수 있는 노이즈(noise)나 지연(delay)을 표현함

**LogRobust**는 50%가 이상 로그라인(anomalous loglines)으로 구성된 학습용 데이터셋(training set)을 사용하여 학습된다. 그러나 실제 환경에서 이상 로그가 드물게 발생하기 때문에, **다량의 이상을 포함한 실제 데이터셋을 구성하는 것은 매우 어렵다**.

또한, **이상 데이터를 인위적으로 생성하거나 주입하는 방식**은 오류 발생 가능성(error-prone)이 높다. 이러한 방식은 모델이 **정상적인 흐름을 학습하기보다는 이상 시퀀스를 구분하는 방법 자체를 학습**하게 만들 위험이 있으며, 이는 **실제 환경에서 시스템의 성능 저하**로 이어질 수 있다.

**LogAnomaly**는 **로그 템플릿의 불안정성(log template instability)** 문제에 대응하기 위해 또 다른 방식을 제안한다. 저자들의 직관은, 새롭게 등장하는 로그 템플릿의 대다수가 기존 템플릿의 단순한 변형(minor variant)일 것이라는 점에 기반한다.

이 시스템은 **LSTM 구조에 입력을 제공하기 위해**, 새로운 템플릿과 기존 템플릿 간의 유사도(similarity)를 계산하여 **가장 적합한 템플릿을 찾는 방식**을 사용한다.

제시된 관련 연구 동향(state of the art)을 바탕으로, **이상 탐지 컴포넌트 설계**를 위해 다음과 같은 실험들을 수행할 계획이다:

- 현재까지의 연구를 바탕으로 볼 때, **LogAnomaly와 LogRobust에 대한 심층 비교 연구**는 존재하지 않는다. 우리는 이 두 접근법을 **이상(anomaly)이 포함되지 않은 데이터셋**으로 학습시켰을 때의 정밀도(precision)를 분석하고자 한다.
- 앞서 제시된 모든 이상 탐지 접근법들은 구조화된 로그(structured logs)를 입력으로 사용하지만, **로그 파싱(log parsing)** 과정은 오류가 없는 단계가 아니다(IV장 참조). 이에 따라 우리는 파싱 과정에서 발생할 수 있는 잠재적 오류에 대해 LSTM 기반 접근법의 견고성(robustness)을 평가할 계획이다.
- LSTM은 **순차적 패턴(sequence)을 학습하는 데 뛰어난 성능**을 보이지만, 다중 소스 환경(multisource environment)에서는 각 소스의 실행 흐름이 뒤섞이게 된다. 이러한 환경에서 LSTM을 **주성분 분석(Principal Component Analysis, PCA)**, **불변성 마이닝(Invariant Mining, IM)**, **로그 클러스터링(Log Clustering)** 등의 방법들과 비교 분석하기 위해, 우리는 해당 환경에서 추출된 데이터셋을 기반으로 실험을 수행할 계획이다.

## IV. LOG PARSING

로그는 **두 부분**으로 나눌 수 있다:

- **헤더(HEADER)**: 타임스탬프(timestamp), 중요도 수준(criticality level), 소스(source) 등과 같은 다양한 필드로 구성되어 있다.

![image.png](image%202.png)

- **메시지(MESSAGE)**: 형식 제약이 없는 텍스트 필드로, 자유 텍스트에 **XML 또는 JSON 형식의 데이터**를 연결(concatenate)하여 **추가 정보를 포함**시킬 수 있다.

앞서 소개된 이상 탐지 모델들은 구조화된 로그 데이터(structured log data)를 사용하였다.

**헤더 필드**는 이미 **사전에 정의된 형식에 따라 구조화**되어 있다.

반면, **메시지 필드**는 정적인 부분(템플릿, template)과 **가변적인 부분(변수, variables)으로 구성된다. 로그 파싱(log parsing)의 주요 도전 과제는 바로 이 두 부분을 **정확히 식별하는 것**에 있다(예: 그림 2 참조).

문헌에는 다양한 알고리즘들이 존재하며, 이들 중 일부는 로그를 **배치(batch)** 단위로 처리하고(예: **IPLoM** [26], **SLCT** [27], **LogCluster** [28]), 다른 일부는 로그를 스트리밍 방식(streaming fashion)으로 처리한다(예: **Drain** [29], **Spell** [30], **Logan** [31], **Logram** [32]).

한편, 본 연구의 맥락에서 **배치 분석 방식**은 다음과 같은 **중대한 한계점**을 가진다:

로그 문장의 불안정성(log statement instability)으로 인해, 아직 등장하지 않은 새로운 로그 템플릿을 포함할 수 없기 때문에 **대표성을 갖춘 학습 데이터셋을 수집하는 것이 불가능**하다.

반면, 로그는 **스트리밍 방식**으로 지속적으로 생성되며, **온라인 파싱(online parsing)** 기법은 실행 중에 **새로운 패턴을 실시간으로 발견**할 수 있다. 더욱이, 온라인 방식은 **고정된 데이터셋**에 대해서도 **더 나은 성능**을 보이는 경향이 있다 [10].

따라서, 우리는 우리의 **로그 파싱 컴포넌트**가 다음과 같은 기능을 갖추기를 원한다:

1. **사람의 개입 없이 자동으로 배포될 수 있을 것**
2. **로그를 스트리밍 방식으로 처리할 수 있을 것**

이와 관련하여, 우리는 온라인 방식의 기법(online methods)에 작업의 초점을 맞추기로 결정하였다. 우리가 확인한 바에 따르면, **기존의 모든 온라인 로그 파싱 알고리즘**은 파라미터(parameter)를 사용하며, 이들 대부분은 **로그라인에 대한 사전 처리(pre-processing)** 기능을 제공한다.

그러나 파라미터 값을 설정하기 위해서는 라벨링된 데이터셋(labeled dataset)이 필요하며, 이는 **비용이 많이 들고 경우에 따라 불가능**한 경우도 있다.

사전 처리 단계에서는 알고리즘이 **URL이나 IP 주소**와 같은 일반적인 변수들을 식별하기 위해 사람이 직접 작성한 정규 표현식(human-crafted regular expressions)을 사용한다. 이 과정은 **전문가의 개입**이 필요하고, **시간이 많이 소요**될 뿐만 아니라 **파싱 효율성에 영향을 줄 수 있는 오류**를 유발할 수 있다.

최근의 연구들 [9], [10], [19]에 따르면, **Drain**이 현재 존재하는 파싱 솔루션 중 **가장 효율적인 방법**으로 평가되고 있다. 우리는 이 접근법을 **분석하고 실험**하였으며, **완전한 자동화를 위한 두 가지 한계점**을 확인하였다 [33]:

- **Drain의 정확도는 사전 처리(preprocessing)에 영향을 받으며**, 이 과정이 잘 정의되지 않은 경우 **정확도가 저하될 수 있다**.
- **Drain은 두 개의 하이퍼파라미터(hyper-parameter)를 사용**하며, 이 값들은 **정밀도(precision)에 상당한 영향을 미친다**.

따라서, Drain은 미지의 시스템(unknown system)**에 대해 **높은 신뢰 수준(high level of confidence)으로 배포되기 어렵다.

온라인 로그 파싱 솔루션에 대한 연구를 확장(By extending our study to other online log parsing solutions)함으로써, 우리는 기존 온라인 로그 파싱 기법들에 대한 벤치마크(benchmark)를 제시하고자 하며, 특히 **자동화 측면에서의 한계점**에 주목하고자 한다.

**Drain 방법**은 가장 우수한 성능을 보이는 것으로 나타났지만, **분산 처리가 불가능**하다는 제한이 있다. 이에 따라, 우리는 이미 **고무적인 초기 결과**를 확보하고 있는 **트리 기반 로그 파싱(tree-based log parsing)** 연구 방식을 분산 환경(distributed environment)에 맞춰 제공할 계획이다.

내부 서비스로부터 수집한 로그를 분석한 결과, 로그 메시지를 구성하는 토큰의 약 **60%가 JSON 또는 XML 형식의 데이터에서 비롯**된다는 사실을 확인하였다. 이와 같은 구조화된 데이터를 로그라인 끝에 추가하는 것은 **API 기반 서비스**에서 **널리 사용되는 관행**이다.

이러한 형식은 로그의 맥락(context)을 이해하는 데 도움이 된다.

예시: "Send 42 bytes to 121.13.4.26 {user id=125, service name=dart vader}"

따라서 우리는 로그 파싱 전에, **구조화된 형식에서 추출 가능한 데이터를 식별하고 분리하는 전처리 단계**를 수행할 것을 제안한다.

이 전처리는 **로그 메시지의 평균 길이를 줄이고**, 로그 파싱 알고리즘의 패턴 탐지율(discovery rate)을 향상시킬 수 있다.

현재 로그 파싱 솔루션을 평가하기 위한 대표적인 기준 지표(reference metrics)는 정확도(accuracy)와 처리 시간(time processing)이다 [10], [36].

표 I을 참고하면, 로그 메시지 **L1과 L3**는 동일한 로그 클래스(log class)에서 유래한 것으로 식별될 경우, **정확하게 분류된 것**으로 간주된다. 이러한 평가지표는 순차적 이상(sequential anomalies)을 탐지할 때 유효하다. 이는 **비정상적인 로그 템플릿 시퀀스**를 탐색하는 작업이기 때문이다.

그러나 정량적 이상(quantitative anomalies)의 경우, 변수 부분(variable parts)이 올바르게 식별되지 않으면 이상 탐지가 불가능하다. 따라서 우리는 로그 메시지 내의 정적(static) 부분과 변수(variable) 부분이 정확히 식별되었는지를 평가할 수 있는 새로운 지표(metric)를 제안하고자 한다.

- 토큰(token)이란, 로그 메시지 내에서 공백(space)으로 구분되는 **연속된 문자열**을 의미한다.

표 I에서, 로그 메시지 **L1과 L2**는 각각 **7개**와 **8개**의 토큰을 가지고 있다.

![image.png](image%203.png)

n개의 파싱된 로그라인 집합(pool)을 고려할 때,

- lil_ili는 **로그라인 i가 포함하는 토큰의 개수**,
- tjt_jtj는 **j번째 토큰의 실제 값(정적 또는 변수)**,
- TjT_jTj는 j번째 토큰의 기대값(expected value)을 나타낸다.

이 지표를 사용하여 기존 로그 파서들의 성능을 평가하면, **로그 메시지로부터 변수(variable)를 추출하는 능력**, 그리고 **정량적 이상(quantitative anomalies)을 탐지하는 데에 있어 그 방법의 타당성**을 보다 잘 이해할 수 있다.

기존의 로그 파싱 성능 평가 지표는 대부분 지도 학습 방식(supervised)에 기반하고 있다. 그러나 **Logan을 소개한 논문**에서는 비지도 학습 방식(unsupervised)의 평가 지표를 제안하였다 [31].

우리는 이 연구를 확장하여, **다른 비지도 학습 기반 지표들**의 타당성 또한 분석할 계획이다 [37].

- 비지도 기반 평가 지표(unsupervised metrics)는 로그 파서의 자동 파라미터 설정(auto-parametrizing)에 있어 매우 유망한 가능성을 제시한다.

이를 바탕으로 다음과 같은 흐름에 따라 동작하는 컴포넌트를 상상할 수 있다:

1. 우선, 해당 컴포넌트는 **자신이 배치된 환경에서 일정량의 로그라인(loglines)을 수집**한다.
2. 그 후, **비지도 기반 평가 지표를 활용하여 자신의 성능을 추정**함으로써 파라미터 값을 보정(calibrate)한다.

![image.png](image%204.png)

1. **최적의 파라미터 값이 탐지되면**, 로그 파싱을 시작한다.

## V. CLASSIFY ANOMALIES

이상(anomaly)은 시스템 장애(breakdown)부터 **성능 문제(performance issue)**, 그리고 보안 공격(security attack)에 이르기까지 다양한 유형의 이벤트일 수 있다.

이와 같이 성격이 서로 다른 이상들은 일반적으로 **동일한 팀에 의해 동일한 우선순위로 처리되지 않는다**.

업무의 우선순위를 정하는 일반적인 방법 중 하나는 이상에 “Low(낮음)”, “Moderate(보통)”, “High(높음)”과 같은 위험도 수준(criticality level)을 부여하는 것이다.

우리가 확인한 바로는, 로그 내의 이상에 대한 자동 분류(automated anomaly classification)에 관한 연구는 **극히 드물다**.

Meng 외(Meng & al.)는 **LogClass**라는 기법을 제안하였으며, 이는 로그 이상에 대해 학습된 분류기(classifier)를 기반으로 한다 [38].

각 조직은 자신들의 업무 도메인에 적합한 로그 클래스(log class)와 위험도 스케일(criticality scale)을 정의할 수 있다.

이러한 주관적 성격(subjective nature)은, 우리가 사용자 정의가 가능하고 지능적인 이상 분류 모듈(customizable and intelligent module for anomaly classification)을 제안하게 된 동기이며, **그 구조는 그림 3에 제시되어 있다**.

우리는 모니터링 팀이 해결 작업(resolution task)을 **효율적으로 할당**할 수 있는 수단을 제공하고자 한다.

이를 위해, 우리의 컴포넌트는 **풀(pool) 시스템**을 기반으로 동작하도록 설계되었다.

초기에는 기본 풀(default pool)만 존재하지만, 관리자(administrator)는 추가적인 풀을 **생성하거나 삭제**할 수 있다.

알림(alert)이 한 풀에서 다른 풀로 이동할 때마다, 이 동작은 특정 풀 내에서의 이상 분류 능력 향상을 위한 학습 신호(assessment signal)로 사용된다.

이와 마찬가지로, **위험도 수준이 수동으로 변경될 때마다**, 이는 향후 이상 평가의 정밀도를 높이는 데 활용된다.

우리는 이러한 유연한 설계(flexible design)가 유지관리자들이 자신들의 이상 처리 절차(anomaly handling process)를 그대로 재현할 수 있도록 도와줄 것으로 기대한다.

또한 이 설계는, 사용자 경험(user experience)에 기반한 수동적 방식(passive manner)으로 분류기에 피드백을 제공할 수 있게 하여, **추가적인 인력 개입 없이도 편리하게 작동**할 수 있는 구조를 제공한다.

## VI. CONCLUSION

본 논문에서는 **MoniLog**를 소개하였다. MoniLog는 클라우드 컴퓨팅 인프라 내에서의 로그 기반 이상 탐지(log-based anomaly detection)를 위한 **자동화된 접근 방식**이다.

우리는 MoniLog의 시스템 설계를 **세 가지 분산형(distributable) 컴포넌트**를 기반으로 구성하였으며, 이로 인해 **확장성(scalability)** 또한 용이하다.

첫 번째 컴포넌트는 로그 메시지를 파싱(parse)하여 **관련 정보를 추출**한다.

이렇게 생성된 구조화된 스트림(structured stream)은 분석되어 이상 시퀀스(anomalous sequences)를 식별하게 된다.

이상이 탐지되면, 해당 이벤트에는 위험도 수준(criticality level)과 클래스(class)가 부여된다.

MoniLog는 로그 문장의 변화(evolution of log statements)에 대해 견고하게 동작하도록 설계되었으며,

**복잡한 로깅 환경(complex logging environments)** 내에서도 **실시간 확장형(real-time scalable)** 이상 탐지를 가능하게 한다.

비록 이 시스템이 **클라우드 컴퓨팅을 위해 설계**되었지만, 우리는 이 접근 방식이 **모든 대규모 온라인 서비스 환경**에도 **유의미하게 적용 가능**하다고 믿는다.

끝으로, 이 연구를 지도해주신 **Raja Chiky 교수님께 깊은 감사의 말씀**을 드린다.

귀중한 시간을 내어주고 **소중한 피드백을 제공해주신 Mar Callau-Zori**께도 특별한 감사를 전한다.

또한, 본 논문을 위한 **연구비를 지원하고 실제 데이터를 포함한 컴퓨팅 자원 및 전문가들과의 협업 기회**를 제공해준 3DS OUTSCALE 및 프랑스 국가연구기구(ANRT)에도 감사드린다.
